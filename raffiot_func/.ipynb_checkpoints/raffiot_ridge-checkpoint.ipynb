{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from proj1_helpers import load_csv_data, predict_labels, create_csv_submission\n",
    "from helpers import *\n",
    "\n",
    "cheminTrain = 'C:/Users/Raphael/Desktop/EPFL/Machine_Learning/train.csv'\n",
    "cheminTest =  'C:/Users/Raphael/Desktop/EPFL/Machine_Learning/test.csv'\n",
    "def compute_mse(y, tx, w):\n",
    "    return (1/(2*tx.shape[0]))*np.linalg.norm(y-tx@w)**2\n",
    "def compute_loss_rmse(y,tx,w):\n",
    "    return (compute_mse(y,tx,w)*2)**0.5\n",
    "def standardize(x):\n",
    "    \"\"\"Standardize the original data set.\"\"\"\n",
    "    mean_x = np.mean(x, axis=0)\n",
    "    x = x - mean_x\n",
    "    std_x = np.std(x, axis=0)\n",
    "    x = x / std_x\n",
    "    return x, mean_x, std_x\n",
    "def standardizeNine(x):\n",
    "    mask = np.any( x == -999, axis=0)\n",
    "    xWithnine = np.copy(x)\n",
    "    columnStandardize = (x[:,mask] == -999).astype(int)\n",
    "    xWithnine[:,mask] = columnStandardize\n",
    "    return xWithnine\n",
    "def build_k_indices(y, k_fold, seed):\n",
    "    num_row = y.shape[0]\n",
    "    interval = int(num_row / k_fold)\n",
    "    np.random.seed(seed)\n",
    "    indices = np.random.permutation(num_row)\n",
    "    k_indices = [indices[k * interval: (k + 1) * interval]\n",
    "                 for k in range(k_fold)]\n",
    "    return np.array(k_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ridge_regression(y, tx, lambda_):\n",
    "    txt = tx.transpose()\n",
    "    lambda_prim = 2*y.shape[0]*lambda_\n",
    "    identity = np.identity(tx.shape[1])\n",
    "    w = np.linalg.inv(txt@tx+lambda_prim*identity)@txt@y\n",
    "    #w= np.linalg.solve(txt@tx+lambda_prim*identity,txt@y)\n",
    "    loss = compute_mse(y,tx,w)\n",
    "    return loss,w"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMPORT DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 138.47    51.655   97.827 ...,    1.24    -2.475  113.497]\n",
      " [ 160.937   68.768  103.235 ..., -999.    -999.      46.226]\n",
      " [-999.     162.172  125.953 ..., -999.    -999.      44.251]\n",
      " ..., \n",
      " [ 105.457   60.526   75.839 ..., -999.    -999.      41.992]\n",
      " [  94.951   19.362   68.812 ..., -999.    -999.       0.   ]\n",
      " [-999.      72.756   70.831 ..., -999.    -999.       0.   ]]\n"
     ]
    }
   ],
   "source": [
    "# load data.\n",
    "yb, input_data, ids = load_csv_data(cheminTrain)\n",
    "yb_test, input_data_test, ids_test = load_csv_data(cheminTest)\n",
    "\n",
    "\n",
    "print(input_data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(250000, 30)\n",
      "(568238, 30)\n",
      "[[   0.      51.655   97.827 ...,    0.       0.     113.497]\n",
      " [   0.      68.768  103.235 ...,    1.       1.      46.226]\n",
      " [   1.     162.172  125.953 ...,    1.       1.      44.251]\n",
      " ..., \n",
      " [   0.      60.526   75.839 ...,    1.       1.      41.992]\n",
      " [   0.      19.362   68.812 ...,    1.       1.       0.   ]\n",
      " [   1.      72.756   70.831 ...,    1.       1.       0.   ]]\n",
      "[[-0.42412233  0.06833197  0.40768027 ..., -1.56404344 -1.56404344\n",
      "   0.4125105 ]\n",
      " [-0.42412233  0.55250482  0.54013641 ...,  0.63936843  0.63936843\n",
      "  -0.27381996]\n",
      " [ 2.35781033  3.19515553  1.09655998 ...,  0.63936843  0.63936843\n",
      "  -0.29396985]\n",
      " ..., \n",
      " [-0.42412233  0.31931645 -0.13086367 ...,  0.63936843  0.63936843\n",
      "  -0.31701723]\n",
      " [-0.42412233 -0.84532397 -0.30297338 ...,  0.63936843  0.63936843\n",
      "  -0.74543941]\n",
      " [ 2.35781033  0.66533608 -0.25352276 ...,  0.63936843  0.63936843\n",
      "  -0.74543941]]\n"
     ]
    }
   ],
   "source": [
    "withoutNine = standardizeNine(input_data)\n",
    "print(input_data.shape)\n",
    "print(input_data_test.shape)\n",
    "whitoutNine_test = standardizeNine(input_data_test)\n",
    "print(withoutNine)\n",
    "x,_,_ = standardize(withoutNine)\n",
    "x_test,_,_ = standardize(whitoutNine_test)\n",
    "print(x)\n",
    "\n",
    "y = (yb + 1) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cross_validation(y, x, k_indices, k, lambda_, degree):\n",
    "\n",
    "    testLine = k_indices[k]\n",
    "    k_indices_prim = np.delete(k_indices,k,0).flatten()\n",
    "    testX = x[testLine]\n",
    "    testY = y[testLine]\n",
    "    trainX = x[k_indices_prim]\n",
    "    trainY = y[k_indices_prim]\n",
    "    \n",
    "    #traintmpX = build_poly(trainX,degree)\n",
    "    #testmpX = build_poly(testX,degree)\n",
    "    \n",
    "    loss, w = ridge_regression(trainY,trainX,lambda_)\n",
    "    loss_tr = compute_mse(trainY,trainX,w)\n",
    "    loss_te = compute_mse(testY,testX,w)\n",
    "    \n",
    "    return w, loss_tr, loss_te"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_poly(x, degree):\n",
    "    \n",
    "    tmp = np.tile(x,(degree+1,1)).transpose()\n",
    "    r = range(degree+1)\n",
    "    return np.power(tmp,r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1,  1,  1,  1],\n",
       "       [ 1,  2,  4,  8],\n",
       "       [ 1,  3,  9, 27]], dtype=int32)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array([1,2,3])\n",
    "build_poly(a,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plots import cross_validation_visualization\n",
    "\n",
    "def cross_validation_demo():\n",
    "    seed = 1\n",
    "    degree = 7\n",
    "    k_fold = 4\n",
    "    lambdas = np.logspace(-4, 0, 30)\n",
    "    \n",
    "    k_indices = build_k_indices(y, k_fold, seed)\n",
    "    \n",
    "    rmse_tr = []\n",
    "    rmse_te = []\n",
    "\n",
    "    for ind, lambda_ in enumerate(lambdas):\n",
    "        loss_tr_total = 0;\n",
    "        loss_te_total = 0;\n",
    "        for k in range(k_fold) :\n",
    "            w,loss_tr,loss_te = cross_validation(y, x, k_indices, k, lambda_, degree)\n",
    "            loss_tr_total += loss_tr\n",
    "            loss_te_total += loss_te\n",
    "\n",
    "        rmse_tr.append(loss_tr_total/k_fold)\n",
    "        rmse_te.append(loss_te_total/k_fold)\n",
    "\n",
    "    cross_validation_visualization(lambdas, rmse_tr, rmse_te)\n",
    "\n",
    "cross_validation_demo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
