{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "import numpy as np\n",
    "from proj1_helpers import predict_labels,load_csv_data, create_csv_submission\n",
    "from helpers import *\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "cheminTrain = 'C:/Users/Raphael/Desktop/EPFL/Machine_Learning/train.csv'\n",
    "cheminTest =  'C:/Users/Raphael/Desktop/EPFL/Machine_Learning/test.csv'\n",
    "\n",
    "yb, input_data, ids = load_csv_data(cheminTrain)\n",
    "yb_test, input_data_test, ids_test = load_csv_data(cheminTest)\n",
    "\n",
    "x,_,_ = standardize(input_data)\n",
    "x_test,_,_ = standardize(input_data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_mse(y, tx, w):\n",
    "    return (1/(2*tx.shape[0]))*np.linalg.norm(y-tx@w)**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def least_squares(y, tx):\n",
    "    txt = tx.transpose()\n",
    "    w= np.linalg.solve(txt@tx,txt@y)\n",
    "    loss = compute_mse(y,tx,w)\n",
    "    \n",
    "    return loss, w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.388952314937\n",
      "\n",
      "\n",
      "[  2.93788271e-02  -2.52531475e-01  -2.54791124e-01  -3.03696823e-02\n",
      "  -1.40144681e+00   2.95701640e-01  -1.07889471e+01   2.67880862e-01\n",
      "  -2.44934975e-03  -3.28822480e+02  -1.82647888e-01   1.14039627e-01\n",
      "   2.05045954e+01   6.38843559e+01  -3.18961917e-04  -1.80884297e-03\n",
      "   6.29935231e+01  -4.48641512e-04   1.54379291e-03   1.21462701e-01\n",
      "   3.95268787e-04  -6.33223473e-02  -2.06747093e-01  -1.16655767e-01\n",
      "   9.86256640e-02   1.67907688e-01  -3.35146213e-02  -2.98358677e+00\n",
      "  -5.36388090e+00   2.78474640e+02]\n",
      "\n",
      "\n",
      "Good prediction :  180029\n",
      "Bad predition :  69971\n",
      "Ratio :  0.720116\n"
     ]
    }
   ],
   "source": [
    "loss, w = least_squares(yb,x)\n",
    "print(loss)\n",
    "print('\\n')\n",
    "print(w)\n",
    "print('\\n')\n",
    "prediction(w,x,yb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def split_data(x, y, ratio, seed=1):\n",
    "\n",
    "    np.random.seed(seed)\n",
    "    N = len(x)\n",
    "\n",
    "    n_train = int(ratio * N)\n",
    "    \n",
    "    train_index = np.random.choice(N, n_train, replace=False)\n",
    "\n",
    "    index = np.arange(N)\n",
    "\n",
    "    mask = np.in1d(index, train_index)\n",
    "\n",
    "    test_index = np.random.permutation(index[~mask])\n",
    "\n",
    "    x_train = x[train_index]\n",
    "    y_train = y[train_index]\n",
    "\n",
    "    x_test = x[test_index]\n",
    "    y_test = y[test_index]\n",
    "\n",
    "    return x_train, y_train, x_test, y_test\n",
    "\n",
    "def prediction(w_train,tx,y_test):\n",
    "    \n",
    "    y_pred1 = predict_labels(w_train,tx)\n",
    "\n",
    "    for n,i in enumerate(y_test):\n",
    "        if i==0:\n",
    "              y_test[n]=-1\n",
    "            \n",
    "    right = 0\n",
    "    wrong = 0\n",
    "\n",
    "    for i in range(len(y_test)):\n",
    "        if y_test[i] == y_pred1[i]:\n",
    "            right +=1 \n",
    "        else:\n",
    "            wrong +=1 \n",
    "    \n",
    "        \n",
    "    print(\"Good prediction : \", right)\n",
    "    print(\"Bad predition : \" , wrong)\n",
    "    print(\"Ratio : \" ,right/len(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare overfit on least squares and ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ridge_regression(y, tx, lambda_):\n",
    "    txt = tx.transpose()\n",
    "    lambda_prim = 2*y.shape[0]*lambda_\n",
    "    identity = np.identity(tx.shape[1])\n",
    "    w = np.linalg.inv(txt@tx+lambda_prim*identity)@txt@y\n",
    "    loss = compute_mse(y,tx,w)\n",
    "    return loss,w\n",
    "def build_poly(x, degree):\n",
    "    y = np.copy(x)\n",
    "    for i in range(1,degree):\n",
    "        y = np.concatenate((y,np.power(x,i+1)),axis=1)\n",
    "                           \n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LEAST SQR\n",
      "0.310624427564\n",
      "\n",
      "\n",
      "[  7.90572620e-01  -2.29644905e-01  -3.47061768e-01   1.18116407e-01\n",
      "   1.83070084e+04  -9.05475762e-01   2.61217945e+05   2.37953262e-01\n",
      "  -3.04868618e-02  -4.48685881e+02  -2.37616255e-01  -8.43610091e-02\n",
      "  -9.54903945e+04   8.71399244e+01  -3.35421373e-04   6.52878210e-03\n",
      "   8.58456401e+01   2.37314147e-03   1.08129274e-02  -8.05879975e-03\n",
      "   5.08798919e-03  -2.41069120e-02  -8.31731341e+04   1.47675491e+01\n",
      "   1.25751155e+05  -5.59550616e+04   8.28302436e+00   8.42289125e+04\n",
      "  -2.82470061e+05   3.80060044e+02  -6.69459615e-02   6.14367548e-02\n",
      "   1.55704702e-02   2.74160392e-02  -1.87441610e+04   2.76667690e-01\n",
      "  -1.66297378e+05  -6.69766560e-02   6.53395451e-03  -1.08215474e-02\n",
      "   4.90159213e-02   1.69188322e-02   1.95527828e+04  -3.30197025e-02\n",
      "  -3.43031017e-02  -9.95021233e-04  -4.39377234e-02  -5.51388757e-02\n",
      "  -2.46795709e-03   3.92958701e-03  -2.29946583e-03  -3.89958596e-02\n",
      "   1.76485363e+05  -1.24810326e+01  -1.64094087e+05   6.88602394e+04\n",
      "  -2.76399416e+00  -6.12359294e+04   1.81135027e+05   1.64041970e-04\n",
      "  -1.93760161e-01  -2.70564268e-03  -1.09240683e-04  -2.02960120e-03\n",
      "   5.49253995e+03  -2.55932444e-02   3.52857282e+04   2.40346315e-02\n",
      "   1.63969058e-04   3.27985753e-03  -2.35187486e-03   1.04499307e-01\n",
      "   4.69860639e+03   7.67613450e-04   4.57047500e-04  -2.79545375e-03\n",
      "   1.67248005e-03  -6.83012967e-04  -4.07962081e-03  -5.64959236e-04\n",
      "  -2.60079241e-03   4.13034482e-03  -6.19342242e+04   3.40882913e+00\n",
      "   7.11113781e+04  -2.82459249e+04   2.62320334e-01   1.46241199e+04\n",
      "  -3.87173487e+04  -2.11910604e-03]\n",
      "\n",
      "\n",
      "Good prediction :  35197\n",
      "Bad predition :  14803\n",
      "Ratio :  0.70394\n",
      "\n",
      "\n",
      "\n",
      "RIDGE R.\n",
      "0.319078872374\n",
      "\n",
      "\n",
      "[  7.68443575e-02  -2.37653848e-01  -1.76256780e-01   8.19787528e-02\n",
      "   1.55624821e-02   1.13025792e-01   1.13642606e-02   1.71436221e-01\n",
      "  -3.05556809e-02   9.41262620e-02  -1.49065213e-01  -1.60325400e-02\n",
      "   1.49898877e-02   2.35650399e-01  -1.06762469e-03   2.86407479e-03\n",
      "   1.54608364e-01   2.06153923e-03   4.53003469e-03   3.02527000e-02\n",
      "   3.12821653e-03  -3.08627157e-02  -9.99867530e-04  -2.06983444e-02\n",
      "  -1.69054627e-02  -1.67183803e-02   1.77266752e-02   1.39518173e-02\n",
      "   1.36042692e-02   2.24273414e-02  -1.61874242e-02   5.85607063e-02\n",
      "  -7.41128631e-03   2.83316477e-02  -2.19702801e-02   1.46105924e-01\n",
      "  -3.50538355e-02  -6.22005675e-02   9.96134186e-03  -1.37327653e-02\n",
      "   3.49653715e-02   4.64931563e-02  -2.37724514e-02  -3.62620468e-02\n",
      "  -3.43028461e-02  -6.53042846e-04  -2.57711872e-02  -6.33558497e-02\n",
      "  -1.53914579e-03  -2.88813526e-03  -1.98334767e-03  -3.81433380e-02\n",
      "  -2.20174441e-02  -4.83556638e-02  -3.35945667e-02  -3.33454948e-02\n",
      "  -1.46487151e-02  -2.70111679e-02  -2.81086691e-02  -3.87300939e-02\n",
      "  -1.75235184e-02  -2.58579538e-03   5.18573737e-04  -1.55340081e-03\n",
      "   1.76671960e-03  -2.29772570e-02  -2.88154592e-02   2.09698888e-02\n",
      "  -4.76566541e-05   3.84018910e-03  -1.70811477e-03   6.51114142e-02\n",
      "  -2.48657856e-03   8.68763460e-04   6.98419744e-04  -1.53210120e-03\n",
      "   8.28127205e-04  -7.23134270e-04  -1.60894456e-03   5.00836695e-05\n",
      "  -2.05943366e-03   4.48047152e-03  -1.76987011e-02  -3.24690453e-02\n",
      "  -3.03564032e-03  -2.79962333e-03   1.88579932e-02  -1.00658748e-02\n",
      "  -1.26647692e-02  -2.40840393e-06]\n",
      "\n",
      "\n",
      "Good prediction :  34566\n",
      "Bad predition :  15434\n",
      "Ratio :  0.69132\n"
     ]
    }
   ],
   "source": [
    "deg = 3\n",
    "lambda_ = 0.008531678524172814\n",
    "x_train, y_train, x_test, y_test = split_data(x, yb, 0.8)\n",
    "x_to_deg = build_poly(x_train,deg)\n",
    "x_to_deg_test = build_poly(x_test,deg)\n",
    "\n",
    "\n",
    "print('LEAST SQR')\n",
    "loss_ls, w_ls = least_squares(y_train,x_to_deg)\n",
    "print(loss_ls)\n",
    "print('\\n')\n",
    "print(w_ls)\n",
    "print('\\n')\n",
    "prediction(w_ls,x_to_deg_test,y_test)\n",
    "\n",
    "print('\\n\\n')\n",
    "print('RIDGE R.')\n",
    "loss_rr, w_rr = ridge_regression(y_train,x_to_deg,lambda_)\n",
    "print(loss_rr)\n",
    "print('\\n')\n",
    "print(w_rr)\n",
    "print('\\n')\n",
    "prediction(w_rr,x_to_deg_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Good prediction :  30001\n",
      "Bad predition :  19999\n",
      "Ratio :  0.60002\n",
      "Current lambda = 1e-15\n",
      "Good prediction :  34400\n",
      "Bad predition :  15600\n",
      "Ratio :  0.688\n",
      "Current lambda = 3.290344562312671e-15\n",
      "Good prediction :  35315\n",
      "Bad predition :  14685\n",
      "Ratio :  0.7063\n",
      "Current lambda = 1.0826367338740562e-14\n",
      "Good prediction :  35152\n",
      "Bad predition :  14848\n",
      "Ratio :  0.70304\n",
      "Current lambda = 3.562247890262451e-14\n",
      "Good prediction :  35137\n",
      "Bad predition :  14863\n",
      "Ratio :  0.70274\n",
      "Current lambda = 1.1721022975334794e-13\n",
      "Good prediction :  35160\n",
      "Bad predition :  14840\n",
      "Ratio :  0.7032\n",
      "Current lambda = 3.8566204211634723e-13\n",
      "Good prediction :  35124\n",
      "Bad predition :  14876\n",
      "Ratio :  0.70248\n",
      "Current lambda = 1.2689610031679235e-12\n",
      "Good prediction :  35091\n",
      "Bad predition :  14909\n",
      "Ratio :  0.70182\n",
      "Current lambda = 4.175318936560409e-12\n",
      "Good prediction :  34995\n",
      "Bad predition :  15005\n",
      "Ratio :  0.6999\n",
      "Current lambda = 1.373823795883261e-11\n",
      "Good prediction :  34895\n",
      "Bad predition :  15105\n",
      "Ratio :  0.6979\n",
      "Current lambda = 4.520353656360241e-11\n",
      "Good prediction :  34827\n",
      "Bad predition :  15173\n",
      "Ratio :  0.69654\n",
      "Current lambda = 1.4873521072935119e-10\n",
      "Good prediction :  34815\n",
      "Bad predition :  15185\n",
      "Ratio :  0.6963\n",
      "Current lambda = 4.893900918477499e-10\n",
      "Good prediction :  34828\n",
      "Bad predition :  15172\n",
      "Ratio :  0.69656\n",
      "Current lambda = 1.6102620275609425e-09\n",
      "Good prediction :  34809\n",
      "Bad predition :  15191\n",
      "Ratio :  0.69618\n",
      "Current lambda = 5.298316906283724e-09\n",
      "Good prediction :  34803\n",
      "Bad predition :  15197\n",
      "Ratio :  0.69606\n",
      "Current lambda = 1.7433288221999908e-08\n",
      "Good prediction :  34799\n",
      "Bad predition :  15201\n",
      "Ratio :  0.69598\n",
      "Current lambda = 5.736152510448681e-08\n",
      "Good prediction :  34789\n",
      "Bad predition :  15211\n",
      "Ratio :  0.69578\n",
      "Current lambda = 1.8873918221350996e-07\n",
      "Good prediction :  34791\n",
      "Bad predition :  15209\n",
      "Ratio :  0.69582\n",
      "Current lambda = 6.210169418915629e-07\n",
      "Good prediction :  34768\n",
      "Bad predition :  15232\n",
      "Ratio :  0.69536\n",
      "Current lambda = 2.043359717856948e-06\n",
      "Good prediction :  34748\n",
      "Bad predition :  15252\n",
      "Ratio :  0.69496\n",
      "Current lambda = 6.723357536499335e-06\n",
      "Good prediction :  34742\n",
      "Bad predition :  15258\n",
      "Ratio :  0.69484\n",
      "Current lambda = 2.21221629107045e-05\n",
      "Good prediction :  34734\n",
      "Bad predition :  15266\n",
      "Ratio :  0.69468\n",
      "Current lambda = 7.27895384398316e-05\n",
      "Good prediction :  34713\n",
      "Bad predition :  15287\n",
      "Ratio :  0.69426\n",
      "Current lambda = 0.00023950266199874908\n",
      "Good prediction :  34692\n",
      "Bad predition :  15308\n",
      "Ratio :  0.69384\n",
      "Current lambda = 0.0007880462815669936\n",
      "Good prediction :  34635\n",
      "Bad predition :  15365\n",
      "Ratio :  0.6927\n",
      "Current lambda = 0.0025929437974046778\n",
      "Good prediction :  34566\n",
      "Bad predition :  15434\n",
      "Ratio :  0.69132\n",
      "Current lambda = 0.008531678524172814\n",
      "Good prediction :  34442\n",
      "Bad predition :  15558\n",
      "Ratio :  0.68884\n",
      "Current lambda = 0.028072162039411815\n",
      "Good prediction :  34081\n",
      "Bad predition :  15919\n",
      "Ratio :  0.68162\n",
      "Current lambda = 0.09236708571873885\n",
      "Good prediction :  33602\n",
      "Bad predition :  16398\n",
      "Ratio :  0.67204\n",
      "Current lambda = 0.30391953823132073\n",
      "Good prediction :  33257\n",
      "Bad predition :  16743\n",
      "Ratio :  0.66514\n",
      "Current lambda = 1.0\n"
     ]
    }
   ],
   "source": [
    "lambdas = np.logspace(-15, 0, 30)\n",
    "for ind, lambda_ in enumerate(lambdas):\n",
    "    loss, w = ridge_regression(y_train,x_to_deg,lambda_)\n",
    "    prediction(w,x_to_deg_test,y_test)\n",
    "    print(\"Current lambda = {i}\".format(i=lambda_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39774.0235781\n",
      "-29622.730225\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(w_ls))\n",
    "print(np.mean(w_rr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
