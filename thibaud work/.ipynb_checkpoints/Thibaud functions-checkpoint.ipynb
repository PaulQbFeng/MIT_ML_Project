{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from proj1_helpers import load_csv_data, predict_labels, create_csv_submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_mse(y, tx, w):\n",
    "    \"\"\"Calculate the loss using mse.\"\"\"\n",
    "    N = y.shape[0]\n",
    "    e = y - tx @ w.T\n",
    "    return 1 / (2 * N) * np.linalg.norm(e) ** 2\n",
    "\n",
    "def compute_gradient(y, tx, w):\n",
    "    \"\"\"Compute the gradient.\"\"\"\n",
    "    N = y.shape[0]\n",
    "    e = y - tx @ w.T\n",
    "    return -1 / N * tx.T @ e \n",
    "\n",
    "def least_squares_GD(y, tx, initial_w, max_iters, gamma):\n",
    "    \"\"\"Least squares using gradient descent algorithm.\"\"\"\n",
    "    w = initial_w\n",
    "    \n",
    "    for _ in range(max_iters):\n",
    "        DL = compute_gradient(y, tx, w)        \n",
    "        w = w - DL * gamma\n",
    "        \n",
    "    return w, compute_mse(y, tx, w)\n",
    "\n",
    "def least_squares_SGD(y, tx, initial_w, batch_size, max_iters, gamma):\n",
    "    \"\"\"Least squares using stochastic gradient descent algorithm.\"\"\"\n",
    "    w = initial_w\n",
    "    \n",
    "    for _ in range(max_iters):        \n",
    "        for yn, txn in batch_iter(y, tx, batch_size):\n",
    "            DL_n = compute_stoch_gradient(yn, txn, w)\n",
    "            w = w - DL_n * gamma\n",
    "                        \n",
    "    return w, compute_mse(y, tx, w)\n",
    "\n",
    "def least_squares(y, tx):\n",
    "    \"\"\"Least squares using normal equation.\"\"\"\n",
    "    a = tx.T @ tx\n",
    "    b = tx.T @ y\n",
    "    w = np.linalg.solve(a, b)\n",
    "    return w, compute_mse(y, tx, w)\n",
    "\n",
    "def ridge_regression(y, tx, lambda_):\n",
    "    \"\"\"Ridge regression.\"\"\"\n",
    "    N = tx.shape[0]\n",
    "    a = (tx.T @ tx) + 2 * N * lambda_ * np.eye(tx.shape[1])\n",
    "    b = tx.T @ y\n",
    "    w = np.linalg.solve(a, b)\n",
    "    return w, compute_mse(y, tx, w)\n",
    "\n",
    "def sigmoid(t):\n",
    "    \"\"\"Sigmoid function on t.\"\"\"\n",
    "    return 1 / (1 + np.exp(-t))\n",
    "\n",
    "def calculate_loss(y, tx, w):\n",
    "    \"\"\"Cost by negative log likelihood.\"\"\"\n",
    "    sigma_tx_w = sigmoid(tx @ w)\n",
    "    sum_terms = y * np.log(sigma_tx_w) + (1 - y) * np.log(sigma_tx_w)\n",
    "    return -sum_terms.sum()\n",
    "\n",
    "def calculate_gradient(y, tx, w):\n",
    "    \"\"\"Gradient of loss.\"\"\"\n",
    "    tx_w = tx @ w\n",
    "    sigma_tx_w = sigmoid(tx_w)\n",
    "    # print('simga_tx_w - y')\n",
    "    # print(sigma_tx_w - y)\n",
    "    grad = tx.T @ (sigma_tx_w - y)\n",
    "    # print('tx.T')\n",
    "    # print(tx.T.shape)\n",
    "    return grad\n",
    "\n",
    "import time\n",
    "\n",
    "def logistic_regression(y, tx, initial_w, max_iters, gamma):\n",
    "    '''Logistic regression.'''\n",
    "    w = initial_w\n",
    "    \n",
    "    for _ in range(max_iters):\n",
    "        # time.sleep(3) \n",
    "        grad = calculate_gradient(y, tx, w)\n",
    "        #print('grad')\n",
    "        #print(grad)\n",
    "        # print('w')\n",
    "        # print(w)\n",
    "        w = w - gamma * grad\n",
    "        \n",
    "    return w, calculate_loss(y, x, w)\n",
    "\n",
    "def reg_logistic_regression(y, tx, lambda_, initial_w, max_iters, gamma):\n",
    "    w = initial_w\n",
    "    \n",
    "    for _ in range(max_iters):\n",
    "        grad = calculate_gradient(y, tx, w) + lambda_ * np.sum(w)\n",
    "        w = w - gamma * grad\n",
    "        \n",
    "    return w, calculate_loss(y, tx, w)\n",
    "\n",
    "def standardize(x):\n",
    "    \"\"\"Standardize the original data set.\"\"\"\n",
    "    mean_x = np.mean(x, axis=0)\n",
    "    x = x - mean_x\n",
    "    std_x = np.std(x, axis=0)\n",
    "    x = x / std_x\n",
    "    return x, mean_x, std_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def split_data(x, y, ratio, seed=None):\n",
    "    \"\"\"\n",
    "    split the dataset based on the split ratio. If ratio is 0.8 \n",
    "    you will have 80% of your data set dedicated to training \n",
    "    and the rest dedicated to testing\n",
    "    \"\"\"\n",
    "    # set seed\n",
    "    if not seed is None:\n",
    "        np.random.seed(seed)\n",
    "    # ***************************************************\n",
    "    # INSERT YOUR CODE HERE\n",
    "    # split the data based on the given ratio: TODO\n",
    "    # ***************************************************\n",
    "    d = x.shape[0]\n",
    "    di = int(d * ratio)\n",
    "    \n",
    "    per = np.random.permutation(d)\n",
    "    \n",
    "    xtraining = x[per][:di]\n",
    "    ytraining = y[per][:di]\n",
    "    xtesting = x[per][di:]\n",
    "    ytesting = y[per][di:]\n",
    "    \n",
    "    return xtraining, ytraining, xtesting, ytesting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_poly(x, degree):\n",
    "    \"\"\"polynomial basis functions for input data x, for j=0 up to j=degree.\"\"\"\n",
    "    # ***************************************************\n",
    "    # INSERT YOUR CODE HERE\n",
    "    # polynomial basis function: TODO\n",
    "    # this function should return the matrix formed\n",
    "    # by applying the polynomial basis to the input data\n",
    "    # ***************************************************\n",
    "    phi = np.ones((x.shape[0], 1))\n",
    "    for deg in range(1, degree+1):\n",
    "        phi = np.c_[phi, x ** deg]\n",
    "    return phi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------\n",
    "# Importing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# yb, input_data, ids = load_csv_data('C:/Users/Thibaud/Documents/data/train.csv', True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "yb_full, input_data_full, ids_full = load_csv_data('C:/Users/Thibaud/Documents/data/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "yb_test, input_data_test, ids_test = load_csv_data('C:/Users/Thibaud/Documents/data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 65381, 148149, 123485, ...,  51225, 177846, 246447])"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "per = np.random.permutation(250000)\n",
    "per"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "yb, input_data, ids = yb_full[per][::10], input_data_full[per][::10], ids_full[per][::10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((25000,), (25000, 30), (25000,))"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yb.shape, input_data.shape, ids.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "------------------------\n",
    "# Treating data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def replace_nans_with_mean(arr, nan=-999):\n",
    "    '''Creates a copy and replaces the nan values by the mean (without those nan values) in the column'''\n",
    "    N, D = arr.shape\n",
    "    copy = arr.copy()\n",
    "    \n",
    "    for d in range(D):\n",
    "        copy[:,d][copy[:,d] == nan] = np.mean(arr[:,d][arr[:,d] != nan])\n",
    "        \n",
    "    return copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def replace_nans_with_most_frequent(arr, nan=-999):\n",
    "    '''Creates a copy and replaces the nan values by the most frequent value in the column'''\n",
    "    N, D = arr.shape\n",
    "    copy = arr.copy()\n",
    "    \n",
    "    for d in range(D):\n",
    "        unique, counts = np.unique(arr[:,d], return_counts=True)\n",
    "        copy[:,d][copy[:,d] == nan] = unique[np.argmax(counts[unique != nan])]\n",
    "        \n",
    "    return copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def replace_nans_with_median(arr, nan=-999):\n",
    "    '''Creates a copy and replaces the nan values by the median (without thos nan values) in the column'''\n",
    "    N, D = arr.shape\n",
    "    copy = arr.copy()\n",
    "    \n",
    "    for d in range(D):\n",
    "        copy[:,d][copy[:,d] == nan] = np.median(arr[:,d][arr[:,d] != nan])\n",
    "        \n",
    "    return copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prediction(w, x_test, y_test, small=-1, big=1, verbose=False):\n",
    "    y_pred = x_test @ w\n",
    "    sep_val = (small + big) / 2\n",
    "    y_pred[y_pred < sep_val] = small\n",
    "    y_pred[y_pred >= sep_val] = big\n",
    "    \n",
    "    bad = np.count_nonzero(y_pred - y_test)\n",
    "    good = y_test.shape[0] - bad\n",
    "    \n",
    "    ratio = good / (good + bad)\n",
    "    \n",
    "    if verbose:\n",
    "        print('Good: ', good)\n",
    "        print('Bad: ', bad)\n",
    "        print('Ratio: ', ratio)\n",
    "    \n",
    "    return ratio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------\n",
    "# Separating data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data separated by the value in column 22 which is a categorical column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "def separate_by_col22(x, idd, y):    \n",
    "    x_22 = [np.delete(x[x[:,22] == i], 22, 1) for i in range(4)]\n",
    "    idd_22 = [idd[x[:,22] == i] for i in range(4)]\n",
    "    y_22 = [y[x[:,22] == i] for i in range(4)]\n",
    "    \n",
    "    return x_22, idd_22, y_22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data_by_22, ids_by_22, yb_by_22 = separate_by_col22(input_data_full, ids_full, yb_full)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seeing the eprcentages of -999 in each column of the separated data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "   0 : 26\n",
      "   4 : 100\n",
      "   5 : 100\n",
      "   6 : 100\n",
      "   12 : 100\n",
      "   22 : 100\n",
      "   23 : 100\n",
      "   24 : 100\n",
      "   25 : 100\n",
      "   26 : 100\n",
      "   27 : 100\n",
      "1\n",
      "   0 : 9\n",
      "   4 : 100\n",
      "   5 : 100\n",
      "   6 : 100\n",
      "   12 : 100\n",
      "   25 : 100\n",
      "   26 : 100\n",
      "   27 : 100\n",
      "2\n",
      "   0 : 5\n",
      "3\n",
      "   0 : 6\n"
     ]
    }
   ],
   "source": [
    "for i_22 in range(4):\n",
    "    print(i_22)\n",
    "    for c in range(input_data_by_22[i_22].shape[1]):\n",
    "        tmp = input_data_by_22[i_22][:,c]\n",
    "        \n",
    "        if np.any(tmp[tmp == -999]):\n",
    "            print('  ', c, ':', int(len(tmp[tmp == -999]) / len(tmp) * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_useless_col(x):\n",
    "    useless_cols = [[4, 5, 6, 12, 22, 23, 24, 25, 26, 27, 28], [4, 5, 6, 12, 25, 26, 27], [], []]\n",
    "    return [np.delete(x[i], useless_cols[i], 1) for i in range(4)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "only_good_data = delete_useless_col(input_data_by_22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((99913,), (25000,))"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yb_by_22[0].shape, yb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.any(only_good_data[3] == -999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def pseudo_cross_validation():\n",
    "    bests = []\n",
    "    \n",
    "    for i_22 in range(4):\n",
    "        print('starting ', i_22)\n",
    "        input_data_clean = replace_nans_with_median(only_good_data[i_22])\n",
    "        input_data_std, _, _ = standardize(input_data_clean)\n",
    "\n",
    "        times = 200\n",
    "        degrees = np.linspace(3, 8, 6).astype(int) # [1, 2, 3]\n",
    "        lambdas = np.logspace(-7, -1, 18) # [0.00001, 0.0001, 0.001, 0.01, 0.1, 1]\n",
    "\n",
    "        rmse_tr = np.zeros([times, len(degrees), len(lambdas)])\n",
    "        rmse_te = np.zeros([times, len(degrees), len(lambdas)])\n",
    "\n",
    "        for time in range(times):\n",
    "            x_tr, y_tr, x_te, y_te = split_data(input_data_std, yb_by_22[i_22], 0.8)\n",
    "\n",
    "            for i, degree in enumerate(degrees):\n",
    "                phi_tr = build_poly(x_tr, degree)\n",
    "                phi_te = build_poly(x_te, degree)\n",
    "\n",
    "                for j, lambda_ in enumerate(lambdas):\n",
    "                    try:\n",
    "                        w, _ = ridge_regression(y_tr, phi_tr, lambda_)\n",
    "\n",
    "                        rmse_tr[time, i, j] = np.sqrt(2 * compute_mse(y_tr, phi_tr, w))\n",
    "                        rmse_te[time, i, j] = np.sqrt(2 * compute_mse(y_te, phi_te, w))\n",
    "                    except:\n",
    "                        rmse_tr[time, i, j] = 1\n",
    "                        rmse_te[time, i, j] = 1\n",
    "\n",
    "            if time == 0.1 * times:\n",
    "                print('  10%')\n",
    "            if time == 0.2 * times:\n",
    "                print('  20%')\n",
    "            if time == 0.3 * times:\n",
    "                print('  30%')\n",
    "            if time == 0.4 * times:\n",
    "                print('  40%')\n",
    "            if time == 0.5 * times:\n",
    "                print('  50%')\n",
    "            if time == 0.6 * times:\n",
    "                print('  60%')\n",
    "            if time == 0.7 * times:\n",
    "                print('  70%')\n",
    "            if time == 0.8 * times:\n",
    "                print('  80%')\n",
    "            if time == 0.9 * times:\n",
    "                print('  90%')\n",
    "            if time == times - 1:\n",
    "                print(' 100%')\n",
    "        \n",
    "        pos = np.unravel_index(np.median(rmse_te, axis=0).argmin(), np.median(rmse_te, axis=0).shape)\n",
    "        bests.append((degrees[pos[0]], lambdas[pos[1]]))\n",
    "        \n",
    "    return bests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def pseudo_cross_validation_2():\n",
    "    bests = []\n",
    "    \n",
    "    for i_22 in range(4):\n",
    "        print('starting ', i_22)\n",
    "        input_data_clean = replace_nans_with_median(only_good_data[i_22])\n",
    "        input_data_std, _, _ = standardize(input_data_clean)\n",
    "        \n",
    "        N = input_data_std.shape[0]\n",
    "\n",
    "        degrees = np.linspace(1, 14, 14).astype(int) # [1, 2, 3]\n",
    "        lambdas = np.logspace(-10, 0, 30) # [0.00001, 0.0001, 0.001, 0.01, 0.1, 1]\n",
    "\n",
    "        predictions = np.zeros([len(degrees), len(lambdas)])\n",
    "\n",
    "        for i, degree in enumerate(degrees):\n",
    "            phi = build_poly(input_data_std, degree)\n",
    "\n",
    "            for j, lambda_ in enumerate(lambdas):\n",
    "                try:\n",
    "                    w, _ = ridge_regression(yb_by_22[i_22], phi, lambda_)\n",
    "\n",
    "                    predictions[i, j] = prediction(w, phi, yb_by_22[i_22])\n",
    "                except:\n",
    "                    print('oops')\n",
    "                    predictions[i, j] = 0\n",
    "        \n",
    "        pos = np.unravel_index(predictions.argmax(), predictions.shape)\n",
    "        bests.append((degrees[pos[0]], lambdas[pos[1]]))\n",
    "        \n",
    "    return bests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting  0\n",
      "starting  1\n",
      "starting  2\n",
      "starting  3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(12, 0.00016102620275609426),\n",
       " (12, 0.0017433288221999908),\n",
       " (14, 7.2789538439831604e-05),\n",
       " (12, 6.2101694189156158e-07)]"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pseudo_cross_validation_2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "bests = _"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(12, 0.00016102620275609426),\n",
       " (12, 0.0017433288221999908),\n",
       " (14, 7.2789538439831604e-05),\n",
       " (12, 6.2101694189156158e-07)]"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bests = [(2, 0.0038566204211634724), (2, 0.03562247890262444), (3, 0.062101694189156162), (2, 0.32903445623126709)] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bests = [(12, 9e-06), (7, 1.65e-05), (10, 2.42e-06), (8, 4e-05)] # 0.800"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bests = [(6, 3.1622776601683792e-06), (6, 2.2758459260747909e-05), (6, 4.3939705607607859e-07), (6, 0.0001)] # 0.804"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------\n",
    "# Creating submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict(w, x_test, small=-1, big=1):\n",
    "    y_pred = x_test @ w\n",
    "    sep_val = (small + big) / 2\n",
    "    y_pred[y_pred < sep_val] = small\n",
    "    y_pred[y_pred >= sep_val] = big\n",
    "    \n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((99913, 29), (99913,))"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_data_full_by_22, ids_full_by_22, yb_full_by_22 = separate_by_col22(input_data_full, ids_full, yb_full)\n",
    "input_data_test_by_22, ids_test_by_22, yb_test_by_22 = separate_by_col22(input_data_test, ids_test, yb_test)\n",
    "\n",
    "input_data_full_by_22[0].shape, yb_full_by_22[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "   0 : 0.2614574679971575\n",
      "   4 : 1.0\n",
      "   5 : 1.0\n",
      "   6 : 1.0\n",
      "   12 : 1.0\n",
      "   22 : 1.0\n",
      "   23 : 1.0\n",
      "   24 : 1.0\n",
      "   25 : 1.0\n",
      "   26 : 1.0\n",
      "   27 : 1.0\n",
      "1\n",
      "   0 : 0.09751882802022077\n",
      "   4 : 1.0\n",
      "   5 : 1.0\n",
      "   6 : 1.0\n",
      "   12 : 1.0\n",
      "   25 : 1.0\n",
      "   26 : 1.0\n",
      "   27 : 1.0\n",
      "2\n",
      "   0 : 0.05859584350622283\n",
      "3\n",
      "   0 : 0.06663959574084101\n"
     ]
    }
   ],
   "source": [
    "for i_22 in range(4):\n",
    "    print(i_22)\n",
    "    for c in range(input_data_full_by_22[i_22].shape[1]):\n",
    "        tmp = input_data_full_by_22[i_22][:,c]\n",
    "        \n",
    "        if np.any(tmp[tmp == -999]):\n",
    "            print('  ', c, ':', len(tmp[tmp == -999]) / len(tmp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Good:  84151\n",
      "Bad:  15762\n",
      "Ratio:  0.8422427511935384\n",
      "Good:  61366\n",
      "Bad:  16178\n",
      "Ratio:  0.7913700608686681\n",
      "Good:  41406\n",
      "Bad:  8973\n",
      "Ratio:  0.8218900732448043\n",
      "Good:  18352\n",
      "Bad:  3812\n",
      "Ratio:  0.8280093845876195\n"
     ]
    }
   ],
   "source": [
    "only_good_data_full = delete_useless_col(input_data_full_by_22)\n",
    "only_good_data_test = delete_useless_col(input_data_test_by_22)\n",
    "\n",
    "for i_22 in range(4):\n",
    "    full_std, _, _ = standardize(only_good_data_full[i_22])\n",
    "    test_std, _, _ = standardize(only_good_data_test[i_22])\n",
    "    \n",
    "    phi_full = build_poly(full_std, bests[i_22][0])\n",
    "    phi_test = build_poly(test_std, bests[i_22][0])\n",
    "    \n",
    "    w, _ = ridge_regression(yb_full_by_22[i_22], phi_full, bests[i_22][1])\n",
    "    \n",
    "    yb_test_by_22[i_22] = predict(w, phi_test)\n",
    "    \n",
    "    prediction(w, phi_full, yb_full_by_22[i_22], verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "yb_submit = np.concatenate(yb_test_by_22)\n",
    "ids_submit = np.concatenate(ids_test_by_22)\n",
    "\n",
    "create_csv_submission(ids_submit, yb_submit, 'submission_by_cat.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6716622260390892"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(yb_submit[yb_submit == -1]) / len(yb_submit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.66352"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(yb[yb == -1]) / len(yb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------\n",
    "# Plotting some stuff and data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sns.set(style=\"whitegrid\", color_codes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "copy_no_nans = replace_nans_with_mean(input_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "et = np.c_[yb, copy_no_nans]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "et"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(et[:10000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The columns that are correlated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = []\n",
    "for i in range(0, 31):\n",
    "    for j in range(i + 1, 31):\n",
    "        corr.append([i, j, df[i].corr(df[j])])\n",
    "        \n",
    "corr_a = np.array(corr)\n",
    "corr_a[np.logical_or(corr_a[:,2] > 0.8, corr_a[:,2] < -0.8)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_no_nans[copy_no_nans[:,8] > 1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(1, 31):\n",
    "    #sns.violinplot(x=0, y=i, data=df)\n",
    "    sns.stripplot(df[0], df[i], jitter=True)\n",
    "    sns.plt.show()\n",
    "    #print(df[0].corr(df[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "grouped = df.groupby(by=[0]).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "grouped.T.to_csv('goruped.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(by=[0]).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
